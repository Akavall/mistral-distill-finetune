
# Task-Based Distillation of Mistral on Chess Opening Knowledge

## Overview  
This project fine-tunes the Mistral-7B-v0.3 model ([mistralai/Mistral-7B-v0.3](https://huggingface.co/mistralai/Mistral-7B-v0.3)) using task-based distillation.  
The training data consists of question-answer (QA) pairs about chess openings, generated by a larger language model such as GPT-4o or Claude 3.5 Sonnet v2.  

## Objective  
The goal is to explore the relationship between:  

- The amount of training data provided to Mistral  
- The quality of responses the fine-tuned model produces  
- How closely the fine-tuned Mistral model can approximate the capabilities of a larger LLM in this specific task  

## Methodology  

### 1. Data Generation  
- Generate question-answer pairs related to chess openings using GPT-4o or Claude 3.5  
- Start with a small dataset (~500 examples) and increase it incrementally to analyze scaling effects  

### 2. Fine-Tuning Mistral  
- Train Mistral-7B-v0.3 on the synthetic QA dataset  
- Use task-based distillation to transfer knowledge from a larger model to Mistral  

### 3. Evaluation  
- Compare fine-tuned Mistral’s responses to the original LLM-generated answers  
- Use a larger LLM (GPT-4o or Claude 3.5 Sonnet v2) to evaluate the fine-tuned model’s results  

## Key Research Question  
How much training data is required for Mistral to approach the response quality of a larger LLM in chess opening knowledge?  

